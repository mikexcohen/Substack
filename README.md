# Mike X Cohen's Substack

I have a Substack :)

https://mikexcohen.substack.com/

My substack posts are each 1000-3000 words (5-15 minutes to read), and focus on topics in machine-learning, LLMs, applied math, and related technical topics.

Each post has an accompanying code file that will reproduce and extend the analyses described in the post. I wrote the code files in Google Colab, and therefore, running then in Colab is the easiest way to ensure reproducibility and library installations.

| Post title |  Code file | Brief description |
|     :---:     |   :---:    | :---: |
| [Correlation vs. cosine similarity](https://mikexcohen.substack.com/p/correlation-vs-cosine-similarity) |  [Correlation_vs_cosineSimilarity.ipynb](https://github.com/mikexcohen/Substack/blob/main/Correlation_vs_cosineSimilarity.ipynb) | Simulate data to learn the math and implementations of correlation and cosine similarity. |
| [Zipf's law in famous fiction: characters and GPT4 tokens](https://mikexcohen.substack.com/p/zipfs-law-in-famous-fiction-characters) |  [ZipfsLaw_charactersTokens.ipynb](https://github.com/mikexcohen/Substack/blob/main/ZipfsLaw_charactersTokens.ipynb) | Explore character and subword (GPT4 tokens) frequencies in famous fiction books. |
| [Drawing text heatmaps to visualize LLM calculations](https://mikexcohen.substack.com/p/drawing-text-heatmaps-to-visualize) |  [textHeatmaps_GPT2.ipynb](https://github.com/mikexcohen/Substack/blob/main/textHeatmaps_GPT2.ipynb) | Learn how to create text heatmaps, and then use them to visualize GPT2 next-token predictions. |
