{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Substack post:</h2>|<h1><a href=\"\" target=\"_blank\">Lessons on life and humor from GPT2</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Teacher:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<i>Using the code without reading the post may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "OxXN_OfqLkFs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EjWotPXSzxp"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GPT2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "s_W8oErYTGjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WqSWx4-MBJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try one of these, or make up your own!\n",
        "prompt = 'Why did the chicken cross the road?'\n",
        "prompt = 'What is the meaning of life?'\n",
        "# prompt = 'What is the origin of the word \"butterfly\"?'\n",
        "\n",
        "# tokenize\n",
        "toks = tokenizer(prompt,return_tensors='pt').to(device)"
      ],
      "metadata": {
        "id": "QhzgDuJaMBHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## generate new output\n",
        "\n",
        "# note that because tokens are randomly generated,\n",
        "# you can re-run this and the next cell to get different wisdom ;)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids      = toks['input_ids'],\n",
        "    attention_mask = toks['attention_mask'],\n",
        "    pad_token_id   = tokenizer.eos_token_id,\n",
        "    max_length     = 200,\n",
        "    num_return_sequences = 1,\n",
        "    do_sample      = True,\n",
        "    top_k          = 50,\n",
        "    top_p          = .95   )"
      ],
      "metadata": {
        "id": "M86W5gkVUeEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "reply_tokens = outputs[0,len(toks[\"input_ids\"][0]):].unsqueeze(0)\n",
        "decoded_txt = tokenizer.batch_decode(reply_tokens)\n",
        "\n",
        "# and print\n",
        "print(f'*Prompt*:\\n  {prompt}\\n')\n",
        "print(f'*Response*:\\n{textwrap.fill(decoded_txt[0],60)}')"
      ],
      "metadata": {
        "id": "cdzXb3jOUReA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGu4AnJjMBBp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}