{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikexcohen/Substack/blob/main/textHeatmaps_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Substack post:</h2>|<h1><a href=\"https://mikexcohen.substack.com/p/drawing-text-heatmaps-to-visualize\" target=\"_blank\">Drawing text heatmaps to visualize LLM calculations</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Teacher:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<i>Using the code without reading the post may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "9FygbivztNGl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTp8j3TJAqvB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# pytorch libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# huggingface LLM\n",
        "from transformers import AutoModelForCausalLM, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this cell only if you're using \"dark mode\"\n",
        "\n",
        "# svg plots (higher-res)\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
        "\n",
        "plt.rcParams.update({\n",
        "    'figure.facecolor': '#383838',\n",
        "    'figure.edgecolor': '#383838',\n",
        "    'axes.facecolor':   '#383838',\n",
        "    'axes.edgecolor':   '#DDE2F4',\n",
        "    'axes.labelcolor':  '#DDE2F4',\n",
        "    'xtick.color':      '#DDE2F4',\n",
        "    'ytick.color':      '#DDE2F4',\n",
        "    'text.color':       '#DDE2F4',\n",
        "    'axes.spines.right': False,\n",
        "    'axes.spines.top':   False,\n",
        "    'axes.titleweight': 'bold',\n",
        "    'axes.labelweight': 'bold'\n",
        "})"
      ],
      "metadata": {
        "id": "dy4A-ah8kzZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KivO-_OF0jJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate the width of one letter"
      ],
      "metadata": {
        "id": "79Q_SJR90jGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(figsize=(10,2))\n",
        "\n",
        "# draw a text object\n",
        "temp_text = ax.text(0,0,'n',fontsize=12,fontfamily='monospace')\n",
        "\n",
        "# get its bounding box in display coordinates\n",
        "bbox = temp_text.get_window_extent(renderer=fig.canvas.get_renderer())\n",
        "\n",
        "# convert from display to axis coordinates\n",
        "inv = ax.transAxes.inverted()\n",
        "bbox_axes = inv.transform([[bbox.x0,bbox.y0], [bbox.x1,bbox.y1]])\n",
        "en_width = bbox_axes[1,0] - bbox_axes[0,0] # bbox is [(x0,y0),(x1,y1)]\n",
        "\n",
        "plt.close(fig)\n",
        "en_width"
      ],
      "metadata": {
        "id": "jZheCSBKeDkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8_EK03a0mBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo: Color words according to character count"
      ],
      "metadata": {
        "id": "OIcMhVsk0l5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some text\n",
        "text = (\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut \"\n",
        "        \"labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris \"\n",
        "        \"nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit \"\n",
        "        \"esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt \"\n",
        "        \"in culpa qui officia deserunt mollit anim id est laborum.\" )\n",
        "\n",
        "# \"tokenize\" the text\n",
        "words = text.split()\n",
        "words"
      ],
      "metadata": {
        "id": "eokEkn1iebIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the lengths of the words and convert to numpy\n",
        "lens = [len(i) for i in words]\n",
        "lens = np.array(lens)\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(lens,'ks',markerfacecolor=[.7,.9,.7])\n",
        "plt.gca().set(xlabel='Word index',ylabel='Word length',title='Raw word counts')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EaG4ZvlexjSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min/max scale\n",
        "charcountsScale = (lens-lens.min()) / (lens.max()-lens.min())\n",
        "\n",
        "# visualize\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(charcountsScale,'kh',markerfacecolor=[.7,.9,.9])\n",
        "plt.gca().set(xlabel='Word index',ylabel='Word length',title='Min-max scaled word counts')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dfGVzbGDsIqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "swlJ5x3xzDfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the heatmap"
      ],
      "metadata": {
        "id": "NFPYeQDzzDcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) initializations\n",
        "x_pos = 0  # starting x position (in axis coordinates)\n",
        "y_pos = 1  # vertical center\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,2),facecolor='w')\n",
        "ax.axis('off')\n",
        "\n",
        "# 2) for-loop\n",
        "for i,word in enumerate(words):\n",
        "\n",
        "  # 3) width of this word\n",
        "  word_width = en_width*len(word)\n",
        "\n",
        "  # 4) colorval is the scaled length of the word\n",
        "  colorval = charcountsScale[i]\n",
        "\n",
        "  # 5) text object with background color matching the scalar value\n",
        "  ax.text(x_pos+word_width/2, y_pos, word, fontsize=12, color='k',\n",
        "          ha='center', va='center',fontfamily='monospace',\n",
        "          bbox = dict(boxstyle='round,pad=.3',\n",
        "          facecolor=mpl.cm.Reds(colorval), edgecolor='none', alpha=.8))\n",
        "\n",
        "  # 6) update x_pos\n",
        "  x_pos += word_width + .015 # plus a small gap\n",
        "\n",
        "  # 7) end of the line; reset coordinates and counter\n",
        "  if x_pos>1.2:\n",
        "    y_pos -= .2\n",
        "    x_pos = 0\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g-XNgq0XxS1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uVZ8DAUefbdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing GPT2"
      ],
      "metadata": {
        "id": "H1_Sjcbh-iDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT2 model and its tokenizer\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# inspect the architecture\n",
        "gpt2"
      ],
      "metadata": {
        "id": "MrCmCVXb-jHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ( \"There are many statistical analyses that quantify bivariate (two variables) \"\n",
        "         \"relationships; in this post I will describe two — correlation and cosine \"\n",
        "         \"similarity — discuss how they relate to each other, and advise you on when \"\n",
        "         \"to use which one. The upshot is that the measures can be identical but are \"\n",
        "         \"often different. Which one to use depends entirely on whether the scale of \"\n",
        "         \"the data is important.\"\n",
        "         )\n",
        "\n",
        "tokens = tokenizer.encode(text,return_tensors='pt')\n",
        "tokens"
      ],
      "metadata": {
        "id": "w5tIJLFEvCkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the outputs of the model\n",
        "outputs = gpt2(tokens)\n",
        "outputs.logits.shape"
      ],
      "metadata": {
        "id": "Hf9DSDMBvCcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The 49th token is \"{tokenizer.decode(tokens[0,48])}\"')\n",
        "print(f'The 50th token is \"{tokenizer.decode(tokens[0,49])}\"')"
      ],
      "metadata": {
        "id": "_zCLOPwqs9C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "# plot the prediction for the next token\n",
        "plt.plot(tokens[0,49],outputs.logits[0,48,tokens[0,49]].item(),'rs',label='Logit for next token')\n",
        "\n",
        "# and all of the tokens\n",
        "plt.plot(outputs.logits[0,48,:].detach(),'h',color=[.3,.3,.3],markerfacecolor=[.7,.9,.7,.3])\n",
        "\n",
        "plt.legend()\n",
        "plt.gca().set(xlabel='Vocab index',ylabel='Logits (raw)',title='Logits from the 49th token',xlim=[-10,50280])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cXqk9J0wtXRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKf0Fpm5s9AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) initialize vector of log-probabilities for each token\n",
        "predicted_logSM = np.zeros(len(tokens[0]))\n",
        "\n",
        "# 2) loop over tokens (skip first)\n",
        "for toki in range(1,len(tokens[0])):\n",
        "\n",
        "  # 3) get the logit outputs and convert to log-softmax\n",
        "  # use the PREVIOUS token position, bc that predicts the current token choice\n",
        "  tokenlogit = outputs.logits[0,toki-1,:]\n",
        "  lsm = F.log_softmax(tokenlogit,dim=-1)\n",
        "\n",
        "  # 4) extract the softmax for the actual token\n",
        "  predicted_logSM[toki] = lsm[tokens[0,toki]].item()"
      ],
      "metadata": {
        "id": "QosrA1uaFDNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min-max scale the predictions\n",
        "y = predicted_logSM[1:] # ignore the first value\n",
        "predicted_logSM[1:] = (y-y.min()) / (y.max()-y.min())"
      ],
      "metadata": {
        "id": "gGgj2Vl_FDKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) initializations\n",
        "x_pos = 0  # starting x position (in axis coordinates)\n",
        "y_pos = 1  # vertical center\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,2),facecolor='w')\n",
        "ax.axis('off')\n",
        "\n",
        "# 2) for-loop\n",
        "for i in range(len(tokens[0])):\n",
        "\n",
        "  # get this token\n",
        "  word = tokenizer.decode(tokens[0,i])\n",
        "\n",
        "  # 3) width of this word\n",
        "  word_width = en_width*len(word)\n",
        "\n",
        "  # 4) colorval is the prediction for this token\n",
        "  colorval = predicted_logSM[i]\n",
        "\n",
        "  # 5) text object with background color matching the scalar value\n",
        "  ax.text(x_pos+word_width/2, y_pos, word, fontsize=12, color='k',\n",
        "          ha='center', va='center',fontfamily='monospace',\n",
        "          bbox = dict(boxstyle='round,pad=.3',\n",
        "          facecolor=mpl.cm.Reds(colorval), edgecolor='none', alpha=.8))\n",
        "\n",
        "  # 6) update x_pos\n",
        "  x_pos += word_width + .015 # plus a small gap\n",
        "\n",
        "  # 7) end of the line; reset coordinates and counter\n",
        "  if x_pos>1.:\n",
        "    y_pos -= .2\n",
        "    x_pos = 0\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f6i8a4iDFDGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TivG9xYiFDA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}