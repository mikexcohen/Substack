{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Substack post:</h2>|<h1><a href=\"\" target=\"_blank\">Two-variable dependence part 1: Covariance</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2><h2>|<h2>Scroll down for parts 2 and 3</h2>|\n",
        "|<h2>Teacher:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<i>Using the code without reading the post may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "nYaI2BjAll-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "SY6PZidRGLvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this cell only if you're using \"dark mode\"\n",
        "\n",
        "# svg plots (higher-res)\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
        "\n",
        "plt.rcParams.update({\n",
        "    'figure.facecolor': '#383838',#'#171717',\n",
        "    'figure.edgecolor': '#383838',#'#171717',\n",
        "    'axes.facecolor':   '#383838',#'#171717',\n",
        "    'axes.edgecolor':   '#DDE2F4',\n",
        "    'axes.labelcolor':  '#DDE2F4',\n",
        "    'xtick.color':      '#DDE2F4',\n",
        "    'ytick.color':      '#DDE2F4',\n",
        "    'text.color':       '#DDE2F4',\n",
        "    'axes.spines.right': False,\n",
        "    'axes.spines.top':   False,\n",
        "    'axes.titleweight': 'bold',\n",
        "    'axes.labelweight': 'bold'\n",
        "})"
      ],
      "metadata": {
        "id": "3NMiHCsejWq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZfcFdakGLsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The code below is for Post 1 (\"Two-variable dependence part 1: Covariance\")\n",
        "\n",
        "### Scroll down for Posts 2 and 3."
      ],
      "metadata": {
        "id": "gJrenErvzv5p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-3fTV91zv2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Figure of examples"
      ],
      "metadata": {
        "id": "Vj-qMhLKHON8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# population correlations\n",
        "popCors = [-.7,0,.7,  0,0,0]\n",
        "\n",
        "# sample size\n",
        "N = 90\n",
        "\n",
        "# create a figure with three subplots\n",
        "_,axs = plt.subplots(2,3,figsize=(10,6.7))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# loop over a range of r values\n",
        "for i,popr in enumerate(popCors):\n",
        "\n",
        "  # linear cases\n",
        "  x = np.random.randn(N)\n",
        "  y = x*popr + np.random.randn(N)*np.sqrt(1-popr**2)\n",
        "\n",
        "  # nonlinear cases\n",
        "  if i==3:\n",
        "    x = np.cos(np.linspace(0,2*np.pi-2*np.pi/N,N))\n",
        "    y = np.sin(np.linspace(0,2*np.pi-2*np.pi/N,N))\n",
        "  elif i==4:\n",
        "    x = np.linspace(-2,2,N)\n",
        "    y = x**2\n",
        "  elif i==5:\n",
        "    x = np.linspace(-2,2,N//2)\n",
        "    y = np.concatenate((x,-x),0)\n",
        "    x = np.concatenate((x,x),0)\n",
        "\n",
        "  # scale up so cov!=cor\n",
        "  x *=2\n",
        "  y += 5\n",
        "\n",
        "  # observed covariance\n",
        "  C = np.cov(x,y)[0,1]\n",
        "\n",
        "  axs[i].plot(x,y,'ko',markersize=10,markerfacecolor=[.7,.9,.7,.5])\n",
        "  axs[i].set(xlabel='Data \"x\"',ylabel='Data \"y\"',title=f'Covariance = {C:.2f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-fZmzozmlCUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B4cyrV3h0v1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example with fake data\n",
        "samplesize = 40\n",
        "n_posts_read = np.random.randint(low=0,high=20,size=samplesize)\n",
        "life_happiness = n_posts_read*3 + np.random.randint(low=0,high=40,size=samplesize)\n",
        "\n",
        "# plot\n",
        "_,axs = plt.subplots(1,2,figsize=(10,4))\n",
        "axs[0].plot(n_posts_read,life_happiness,'wh',markersize=10,markerfacecolor=[.7,.7,.9,.5])\n",
        "axs[0].set(xlabel=\"Number of Mike's posts read\",xticks=range(0,21,4),\n",
        "              ylabel='Life happiness',title='Posts read vs. happiness, raw data')\n",
        "\n",
        "axs[1].plot(n_posts_read-n_posts_read.mean(),life_happiness-life_happiness.mean(),'wh',markersize=10,markerfacecolor=[.7,.7,.9,.5])\n",
        "axs[1].axhline(0,color='gray',linestyle='--')\n",
        "axs[1].axvline(0,color='gray',linestyle='--')\n",
        "axs[1].set(xlabel=\"Number of Mike's posts read\",xticks=range(-10,11,4),\n",
        "              ylabel='Life happiness',title='Mean-centered data')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YttPkF6N6WPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66eVfykRHOKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 1: Covariance in simulated data"
      ],
      "metadata": {
        "id": "3wsWaAWwGUQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the variables\n",
        "N = 300\n",
        "x = np.random.normal(10,4,N)\n",
        "y = x + np.random.normal(20,11,N)\n",
        "\n",
        "# calculate covariance\n",
        "x_centered = x-x.mean()\n",
        "y_centered = y-y.mean()\n",
        "cov = np.sum( x_centered*y_centered )\n",
        "cov /= N-1\n",
        "\n",
        "# numpy implementation\n",
        "cov_np = np.cov(x,y)[0,1]\n",
        "\n",
        "print(f'Covariance (manual) = {cov:.4f}')\n",
        "print(f'Covariance (numpy)  = {cov_np:.4f}')"
      ],
      "metadata": {
        "id": "0vkCbR4rGLpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and visualize\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(x,y,'wh',markeredgewidth=.5,markerfacecolor=[.9,.7,.7,.7])\n",
        "plt.gca().set(xlabel='$x$',ylabel='$y$',title=f'Covariance = {cov:.2f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1FPahGEFJmCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdUuYdydGLmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 2: Covariance to correlation"
      ],
      "metadata": {
        "id": "Kxthh4xDGLi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same variables, but scaling impacts their covariance\n",
        "print(f'Covariance unscaled:   {np.cov(x,y)[0,1]:.4f}')\n",
        "print(f'Covariance x scaled:   {np.cov(x*10,y)[0,1]:.4f}')\n",
        "print(f'Covariance x,y scaled: {np.cov(x*10,y*10)[0,1]:.4f}')"
      ],
      "metadata": {
        "id": "NG9SAl6sCH_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# translating the math into code\n",
        "corr = cov / np.sqrt( x.var(ddof=1)*y.var(ddof=1) )\n",
        "\n",
        "# via numpy\n",
        "corr_np = np.corrcoef(x,y)[0,1]\n",
        "\n",
        "print(f'Correlation (manual) = {corr:.4f}')\n",
        "print(f'Correlation (numpy)  = {corr_np:.4f}')"
      ],
      "metadata": {
        "id": "VjcdIAM0KGSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling has no impact on correlation\n",
        "print(f'Correlation unscaled:   {np.corrcoef(x,y)[0,1]:.4f}')\n",
        "print(f'Correlation x scaled:   {np.corrcoef(x*10,y)[0,1]:.4f}')\n",
        "print(f'Correlation x,y scaled: {np.corrcoef(x*10,y*10)[0,1]:.4f}')"
      ],
      "metadata": {
        "id": "SBAktIr9Cuik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHka0FZcKGPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 3: Statistical significance via permutation testing"
      ],
      "metadata": {
        "id": "tfbBq3bRKGMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how to use permutation()\n",
        "np.random.permutation(5)"
      ],
      "metadata": {
        "id": "NjflZ5gjPdAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one permuted covariance\n",
        "shuffle_idx = np.random.permutation(N)\n",
        "np.cov( x[shuffle_idx],y )[0,1]"
      ],
      "metadata": {
        "id": "_RPJUPNZKGJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a distribution of H0 values\n",
        "n_iters = 1000\n",
        "permuted_covs = np.zeros(n_iters)\n",
        "\n",
        "# loop over the shufflings\n",
        "for i in range(n_iters):\n",
        "  shuffle_idx = np.random.permutation(N)\n",
        "  permuted_covs[i] = np.cov( x[shuffle_idx],y )[0,1]\n",
        "\n",
        "# get statistical values\n",
        "zval = (cov-permuted_covs.mean()) / permuted_covs.std(ddof=1)\n",
        "pval = np.sum( permuted_covs > cov ) / n_iters"
      ],
      "metadata": {
        "id": "Q8eqzvy5KGFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the distribution\n",
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "plt.hist(permuted_covs,bins=40,color=[.9,.7,.7],edgecolor=[[.7,.7,.7]],label='Shuffled')\n",
        "plt.axvline(cov,color='lightblue',linestyle='--',linewidth=2,label='Observed')\n",
        "\n",
        "plt.gca().set(xlabel='Covariance value',ylabel='Count',\n",
        "              title=f'Permutation test\\nz = {zval:.2f}, p = {pval:.2f}')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vBRlkbPaOZ2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJ9rE-zjKGCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 4: Impact of outliers"
      ],
      "metadata": {
        "id": "Js4jiztZGLf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a copy of the data and create an outlier\n",
        "x_hasOut = x + 0\n",
        "x_hasOut[-1] = x_hasOut[-1]*5\n",
        "\n",
        "y_hasOut = y + 0\n",
        "y_hasOut[1] = y_hasOut[1]*5\n",
        "\n",
        "print(f'Covariance (original)  = {np.cov(x,y)[0,1]:.4f}')\n",
        "print(f'Covariance (x-outlier) = {np.cov(x_hasOut,y)[0,1]:.4f}')\n",
        "print(f'Covariance (y-outlier) = {np.cov(x_hasOut,y_hasOut)[0,1]:.4f}')"
      ],
      "metadata": {
        "id": "IE5F-_lKRdFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and visualize\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(x_hasOut,y_hasOut,'wh',markeredgewidth=.5,markerfacecolor=[.9,.7,.7,.7])\n",
        "plt.gca().set(xlabel='x',ylabel='y',title=f'Covariance = {np.cov(x_hasOut,y_hasOut)[0,1]:.2f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KRqapcZORdCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate z-scores and significance threshold\n",
        "x_z = (x_hasOut-x_hasOut.mean()) / x_hasOut.std(ddof=1)\n",
        "y_z = (y_hasOut-y_hasOut.mean()) / y_hasOut.std(ddof=1)\n",
        "\n",
        "zThresh = 4\n",
        "\n",
        "# and visualize\n",
        "_,axs = plt.subplots(1,2,figsize=(10,4))\n",
        "axs[0].plot(x_hasOut,y_hasOut,'wh',markeredgewidth=.5,markerfacecolor=[.9,.7,.7,.7])\n",
        "axs[0].set(xlabel='x',ylabel='y',title=f'Original scale\\nCovariance = {np.cov(x_hasOut,y_hasOut)[0,1]:.2f}')\n",
        "\n",
        "axs[1].plot(x_z,y_z,'wh',markeredgewidth=.5,markerfacecolor=[.9,.7,.7,.7])\n",
        "axs[1].set(xlabel='$Z_x$',ylabel='$z_y$',title=f'Z-scored\\nCovariance = {np.cov(x_z,y_z)[0,1]:.2f}')\n",
        "axs[1].axhline(zThresh,color='gray',linestyle='--',linewidth=.5)\n",
        "axs[1].axvline(zThresh,color='gray',linestyle='--',linewidth=.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iKgkBXN-Rc_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identify outliers\n",
        "outliers = (abs(x_z)>zThresh) | (abs(y_z)>zThresh)\n",
        "\n",
        "# it's a boolean\n",
        "outliers"
      ],
      "metadata": {
        "id": "z1Gu8O0WRc5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove outliers into new variables\n",
        "x_clean = x_hasOut[~outliers]\n",
        "y_clean = y_hasOut[~outliers]\n",
        "\n",
        "# recalculate covariances\n",
        "orig_cov = np.cov(x,y)[0,1]\n",
        "hasOut_cov = np.cov(x_hasOut,y_hasOut)[0,1]\n",
        "clean_cov = np.cov(x_clean,y_clean)[0,1]\n",
        "\n",
        "print(f'Original covariance: {orig_cov:.2f}')\n",
        "print(f'With outliers:       {hasOut_cov:.2f}')\n",
        "print(f'Cleaned covariance:  {clean_cov:.2f}')"
      ],
      "metadata": {
        "id": "bIURW43YRc2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7EY5SC5xtOIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1qTK3X-0RczP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Substack post:</h2>|<h1><a href=\"\" target=\"_blank\">Two-variable dependence part 2: Mutual information</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2><h2>|<h2>Scroll down for part 3</h2>|\n",
        "|<h2>Teacher:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<i>Using the code without reading the post may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "a-_Uu4d8z_Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q7c2lcP_3F56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# population correlations\n",
        "popCors = [-.7,0,.7,0,0,0]\n",
        "\n",
        "# sample size\n",
        "N = 90\n",
        "\n",
        "# create a figure with three subplots\n",
        "_,axs = plt.subplots(2,3,figsize=(10,6.7))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# loop over a range of r values\n",
        "for i,popr in enumerate(popCors):\n",
        "\n",
        "  # linear cases\n",
        "  x = np.random.randn(N)\n",
        "  y = x*popr + np.random.randn(N)*np.sqrt(1-popr**2)\n",
        "\n",
        "  # nonlinear cases\n",
        "  if i==3:\n",
        "    x = np.cos(np.linspace(0,2*np.pi-2*np.pi/N,N))\n",
        "    y = np.sin(np.linspace(0,2*np.pi-2*np.pi/N,N))\n",
        "  elif i==4:\n",
        "    x = np.linspace(-2,2,N)\n",
        "    y = x**2\n",
        "  elif i==5:\n",
        "    x = np.linspace(-2,2,N//2)\n",
        "    y = np.concatenate((x,-x),0)\n",
        "    x = np.concatenate((x,x),0)\n",
        "\n",
        "  x *=2\n",
        "  y += 5\n",
        "\n",
        "  # observed covariance\n",
        "  C = np.cov(x,y)[0,1]\n",
        "\n",
        "  # observed mutual information\n",
        "  mi = mutual_info_regression(x.reshape(-1,1),y)\n",
        "\n",
        "  axs[i].plot(x,y,'ko',markersize=10,markerfacecolor=[.7,.9,.7,.5])\n",
        "  axs[i].set(xlabel='Data \"x\"',ylabel='Data \"y\"',\n",
        "             title=f'Covariance = {C:.2f}\\nMutual information = {mi[0]:.2f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G6ZLNS0PGLdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Cw4PaJZ0AGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 1: Entropy in categorical variables"
      ],
      "metadata": {
        "id": "I9AtBbDA91F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate non-normal distributed category labels\n",
        "x = np.random.uniform(low=0,high=3,size=200)**2\n",
        "x = np.ceil(x).astype(int)\n",
        "\n",
        "# convert to probability\n",
        "p_x = np.bincount(x) / len(x)\n",
        "\n",
        "# calculate entropy\n",
        "eps = 1e-13\n",
        "entropy_x = -np.sum( p_x * np.log2(p_x+eps) )\n",
        "\n",
        "# min-max scale for coloring\n",
        "p4color = (p_x-p_x.min()) / (p_x.max()-p_x.min())\n",
        "\n",
        "# and plot :)\n",
        "_,axs = plt.subplots(1,2,figsize=(12,3))\n",
        "\n",
        "# plot each data label according to frequency\n",
        "for i in range(len(p_x)):\n",
        "  axs[0].plot(np.where(x==i)[0],x[x==i],'ws',markeredgewidth=.2,markersize=5,markerfacecolor=mpl.cm.plasma(p4color[i]),alpha=.6)\n",
        "  axs[1].bar(i,p_x[i],color=mpl.cm.plasma(p4color[i]))\n",
        "\n",
        "axs[0].set(xlabel='Data index',ylabel='Category',title='Scatter plot')\n",
        "axs[1].set(xlabel='Data values',ylabel='Proportion',xlim=[np.min(x)-.5,np.max(x)+.5],\n",
        "              title=f'Distribution (entropy = {entropy_x:.3f})')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d48Aq3MY9090"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCHwOZKq906z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 2: Entropy in continuous variables"
      ],
      "metadata": {
        "id": "yPl4omLr94U6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 347\n",
        "x = np.linspace(.001,2.5,N)\n",
        "y = np.cos(2*x)*3 + np.log(x) + np.random.normal(0,.5,N)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(x,y,'ko',markersize=10,markerfacecolor=[.9,.7,.7,.5])\n",
        "plt.gca().set(xlabel='Data $x$',ylabel='Data $y$',\n",
        "              title=r'$y = 3\\cos(2x) + \\ln(x) + \\mathcal{N}(0,.5)$')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hdKna0aQ96ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uh oh...\n",
        "# np.bincount(y)"
      ],
      "metadata": {
        "id": "bMzY5r6cypnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to probability\n",
        "p_y,p_x = np.histogram(y,bins=30,density=True)\n",
        "\n",
        "# calculate entropy\n",
        "entropy_y = -np.sum( p_y * np.log2(p_y+eps) )\n",
        "\n",
        "# min-max scale for coloring\n",
        "p4color = (p_y-p_y.min()) / (p_y.max()-p_y.min())\n",
        "\n",
        "# and plot :)\n",
        "_,axs = plt.subplots(1,2,figsize=(12,4))\n",
        "\n",
        "# plot each data label according to frequency\n",
        "for i in range(len(p_y)):\n",
        "\n",
        "  # find the values within these bin boundaries\n",
        "  whichvals = (y>=p_x[i]) & (y<p_x[i+1])\n",
        "\n",
        "  # plot the data and probability\n",
        "  axs[0].plot(np.where(whichvals)[0],y[whichvals],'ws',markeredgewidth=.2,markersize=6,markerfacecolor=mpl.cm.plasma(p4color[i]),alpha=.8)\n",
        "  axs[1].bar(p_x[i],p_y[i],width=(p_x[1]-p_x[0])*.9,color=mpl.cm.plasma(p4color[i]))\n",
        "\n",
        "axs[0].set(xlabel='Data index',ylabel='Data value',title='Scatter plot')\n",
        "axs[1].set(xlabel='Data values',ylabel='Proportion',xlim=[p_x[0]-.5,p_x[-1]+.5],\n",
        "              title=f'Distribution (entropy = {entropy_x:.3f})')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o73JStLvHJYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbins = np.arange(5,51)\n",
        "H_by_bins = np.zeros(len(nbins))\n",
        "\n",
        "for i in range(len(H_by_bins)):\n",
        "  p_y,p_x = np.histogram(y,bins=nbins[i],density=True)\n",
        "  H_by_bins[i] = -np.sum( p_y * np.log2(p_y+eps) )\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,3))\n",
        "plt.plot(nbins,H_by_bins,'wh',markersize=10,markerfacecolor=[.7,.7,.9])\n",
        "plt.gca().set(xlabel='Number of bins',ylabel='Entropy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D-HYor_N4JhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w36jYBixHJUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 3: Joint entropy and mutual information"
      ],
      "metadata": {
        "id": "nkKMhclO-QL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D histogram\n",
        "Z,xx,yy = np.histogram2d(x,y,bins=8)\n",
        "\n",
        "_,axs = plt.subplots(1,2,figsize=(12,4))\n",
        "axs[0].plot(x,y,'ro',markeredgewidth=.3,markerfacecolor=[.7,.7,.9,.7])\n",
        "axs[0].set(xlabel='x',ylabel='y',title='Full resolution data')\n",
        "\n",
        "h = axs[1].imshow(Z.T,extent=[xx[0],xx[-1],yy[0],yy[-1]],vmin=0,vmax=Z.max()*.7,origin='lower',aspect='auto',cmap='hot')\n",
        "axs[1].set(xlabel='x',ylabel='y',title='Discretized (binned) data')\n",
        "axs[1].plot(x,y,'wo',markerfacecolor=[.4,.4,.4],alpha=.7)\n",
        "plt.colorbar(h,ax=axs[1],pad=.01,label='Count')\n",
        "plt.suptitle('Z,xx,yy = np.histogram2d(x,y,bins=8)', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iWh0DGkiKEQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D discretization\n",
        "Z = np.histogram2d(x,y,bins=8)[0]\n",
        "\n",
        "# joint entropy from proportion\n",
        "p_Z = Z / Z.sum()\n",
        "entropy_Z = -np.sum( p_Z * np.log2(p_Z+eps) )\n",
        "\n",
        "# single-variable entropies\n",
        "p_x = np.sum(p_Z, axis=1)\n",
        "entropy_x = -np.sum( p_x * np.log2(p_x+eps) )\n",
        "p_y = np.sum(p_Z, axis=0)\n",
        "entropy_y = -np.sum( p_y * np.log2(p_y+eps) )\n",
        "\n",
        "print(f'Entropy of x: {entropy_x:.2f}')\n",
        "print(f'Entropy of y: {entropy_y:.2f}')\n",
        "print(f'Entropy of Z: {entropy_Z:.2f}')"
      ],
      "metadata": {
        "id": "QN1ozFUwB3uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mutual information via direct translation of the formula\n",
        "miEps = (entropy_x+entropy_y) - entropy_Z"
      ],
      "metadata": {
        "id": "XtIQJ72y0ADD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# via sklearn's MI function optimized for continuous variables\n",
        "miSk = mutual_info_regression(x.reshape(-1,1),y)[0]\n",
        "\n",
        "print(f'Mutual information (manual) : {miEps:.2f}')\n",
        "print(f'Mutual information (sklearn): {miSk:.2f}')"
      ],
      "metadata": {
        "id": "uy-y2hy9MdlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsfdI0dVz__x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impact of discretization\n",
        "\n",
        "bincounts = np.arange(4,25)\n",
        "mi_by_bincount = np.zeros(len(bincounts))\n",
        "\n",
        "for i in range(len(mi_by_bincount)):\n",
        "\n",
        "  Z,xx,yy = np.histogram2d(x,y,bins=bincounts[i])\n",
        "\n",
        "  # proportion via sum-scaling\n",
        "  p_Z = Z / Z.sum()\n",
        "  p_x = np.sum(p_Z, axis=1)\n",
        "  p_y = np.sum(p_Z, axis=0)\n",
        "\n",
        "  # calculate entropy\n",
        "  eps = 1e-13\n",
        "  entropy_x = -np.sum( p_x * np.log2(p_x+eps) )\n",
        "  entropy_y = -np.sum( p_y * np.log2(p_y+eps) )\n",
        "\n",
        "  # as difference of entropies\n",
        "  entropy_Z = -np.sum( p_Z * np.log2(p_Z+eps) )\n",
        "  mi_by_bincount[i] = (entropy_x+entropy_y) - entropy_Z\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(bincounts,mi_by_bincount,'wh',markersize=10,markerfacecolor=[.7,.7,.9])\n",
        "plt.axhline(miSk,color=[.9,.7,.7],linestyle='--',linewidth=2,label='Scikit-learn')\n",
        "plt.gca().set(xticks=bincounts[::2],xlabel='Number of bins',ylabel='Mutual information')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VrWiPZf4-Udt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELdsA-AiM3WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 4: Statistical significance via permutation testing"
      ],
      "metadata": {
        "id": "kRanKM36M3TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a distribution of H0 values\n",
        "n_iters = 1000\n",
        "permuted_mis = np.zeros(n_iters)\n",
        "\n",
        "# loop over the shufflings\n",
        "for i in range(n_iters):\n",
        "  shuffle_idx = np.random.permutation(N)\n",
        "  x_shuffled = x[shuffle_idx].reshape(-1,1)\n",
        "  permuted_mis[i] = mutual_info_regression(x_shuffled,y)[0]\n",
        "\n",
        "# get statistical values\n",
        "zval = (miSk-permuted_mis.mean()) / permuted_mis.std(ddof=1)\n",
        "pval = np.sum( permuted_mis > miSk ) / n_iters"
      ],
      "metadata": {
        "id": "glUfE0KcM3Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the distribution\n",
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "plt.hist(permuted_mis,bins=40,color=[.9,.7,.7],edgecolor=[[.7,.7,.7]],label='Shuffled')\n",
        "plt.axvline(miSk,color='lightblue',linestyle='--',linewidth=2,label='Observed')\n",
        "\n",
        "plt.gca().set(xlabel='Mutual information value',ylabel='Count (log)',xlim=[-.01,None],yscale='log',\n",
        "              title=f'Permutation test\\nz = {zval:.2f}, p = {pval:.2f}')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TVZ1ZbViv9wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zsvWDrxMM3LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 5: Impact of outliers"
      ],
      "metadata": {
        "id": "pFZyrBkPM3H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mi(x,y):\n",
        "\n",
        "  # histogram to calculate proportion\n",
        "  Z,xx,yy = np.histogram2d(x,y,bins=7)\n",
        "\n",
        "  # proportion via sum-scaling\n",
        "  p_Z = Z / Z.sum()\n",
        "  p_x = np.sum(p_Z, axis=1)\n",
        "  p_y = np.sum(p_Z, axis=0)\n",
        "\n",
        "  # calculate entropy\n",
        "  eps = 1e-13\n",
        "  entropy_x = -np.sum( p_x * np.log2(p_x+eps) )\n",
        "  entropy_y = -np.sum( p_y * np.log2(p_y+eps) )\n",
        "\n",
        "  # as difference of entropies\n",
        "  entropy_Z = -np.sum( p_Z * np.log2(p_Z+eps) )\n",
        "  miEps = (entropy_x+entropy_y) - entropy_Z\n",
        "\n",
        "  miSk = mutual_info_regression(x.reshape(-1,1),y)[0]\n",
        "\n",
        "  return miEps,miSk"
      ],
      "metadata": {
        "id": "uJzgVTP2DJrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a copy of the data and create an outlier\n",
        "x_hasOut = x + 0\n",
        "x_hasOut[-1] = x_hasOut[-1]*5\n",
        "\n",
        "y_hasOut = y + 0\n",
        "y_hasOut[1] = y_hasOut[1]*5\n",
        "\n",
        "# original\n",
        "mi1,mi2 = calculate_mi(x,y)\n",
        "print('NO OUTLIERS:')\n",
        "print(f'  Manual  = {mi1:.2f}')\n",
        "print(f'  SKlearn = {mi2:.2f}')\n",
        "\n",
        "# outlier in x (not in y)\n",
        "mi1,mi2 = calculate_mi(x_hasOut,y)\n",
        "print('\\nOUTLIER in x:')\n",
        "print(f'  Manual  = {mi1:.2f}')\n",
        "print(f'  SKlearn = {mi2:.2f}')\n",
        "\n",
        "# outlier in y (not in x)\n",
        "mi1,mi2 = calculate_mi(x,y_hasOut)\n",
        "print('\\nOUTLIER in y:')\n",
        "print(f'  Manual  = {mi1:.2f}')\n",
        "print(f'  SKlearn = {mi2:.2f}')\n",
        "\n",
        "# outliers in x and y\n",
        "mi1,mi2 = calculate_mi(x_hasOut,y_hasOut)\n",
        "print('\\nOUTLIERS in both:')\n",
        "print(f'  Manual  = {mi1:.2f}')\n",
        "print(f'  SKlearn = {mi2:.2f}')"
      ],
      "metadata": {
        "id": "XjEWLiQOM9wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,3))\n",
        "plt.plot(x_hasOut,y_hasOut,'ko',markersize=10,markerfacecolor=[.9,.7,.9,.5])\n",
        "plt.gca().set(xlabel='Data $x$',ylabel='Data $y$',title='Data with outliers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MCTmoMFQEM1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ZiPrUajEMyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Substack post:</h2>|<h1><a href=\"\" target=\"_blank\">Two-variable dependence part 3: Covariance vs. mutual information</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2><h2>|<h2> </h2>|\n",
        "|<h2>Teacher:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<i>Using the code without reading the post may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "g1vGXTUIeh2D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmhgVBC3P9ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 1: Covariance and mutual information in simulated data"
      ],
      "metadata": {
        "id": "aRFm2oXxbLpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# population correlation coefficients\n",
        "rs = np.linspace(-.9,.9,100)\n",
        "\n",
        "# sample size\n",
        "N = 500\n",
        "\n",
        "# initialize output matrix\n",
        "covmi = np.zeros((len(rs),2))\n",
        "\n",
        "\n",
        "# loop over a range of r values\n",
        "for ri in range(len(rs)):\n",
        "\n",
        "  ### generate data\n",
        "  x = np.random.randn(N)\n",
        "  y = x*rs[ri] + np.random.randn(N)*np.sqrt(1-rs[ri]**2)\n",
        "\n",
        "  ### compute covariance\n",
        "  covmi[ri,0] = np.cov(x,y)[0,1]\n",
        "\n",
        "  ### compute mutual information\n",
        "  covmi[ri,1] = mutual_info_regression(x.reshape(-1,1),y)[0]\n",
        "\n",
        "\n",
        "## visualize the results\n",
        "_,axs = plt.subplots(2,2,figsize=(10,7))\n",
        "\n",
        "axs[0,0].plot(rs,covmi[:,0],'rs',markersize=8,markerfacecolor=[.9,.7,.7,.5],label='Covariance')\n",
        "axs[0,0].plot(rs,covmi[:,1],'bo',markersize=8,markerfacecolor=[.7,.7,.9,.5],label='Mutual information')\n",
        "axs[0,0].legend()\n",
        "axs[0,0].set(xlabel='Population correlation',ylabel=r'Measured $c$ or MI',title='Covariance and mutual information')\n",
        "\n",
        "axs[0,1].plot(covmi[:,0],covmi[:,1],'ks',markersize=8,markerfacecolor=[.7,.9,.7,.5])\n",
        "axs[0,1].axhline(y=0,color='gray',linestyle='--')\n",
        "axs[0,1].axvline(x=0,color='gray',linestyle='--')\n",
        "axs[0,1].set(xlabel='Covariance',ylabel='Mutual information',title=f'$r=${np.corrcoef(covmi.T)[1,0]:.2f}')\n",
        "\n",
        "\n",
        "axs[1,0].plot(rs,covmi[:,0]**2,'rs',markersize=8,markerfacecolor=[.9,.7,.7,.5],label='(covariance)$^2$')\n",
        "axs[1,0].plot(rs,covmi[:,1],'bo',markersize=8,markerfacecolor=[.7,.7,.9,.5],label='Mutual information')\n",
        "axs[1,0].legend()\n",
        "axs[1,0].set(xlabel='Population correlation',ylabel=r'Measured $c^2$ or MI',title='Squared covariance and mutual information')\n",
        "\n",
        "axs[1,1].plot(covmi[:,0]**2,covmi[:,1],'ks',markersize=8,markerfacecolor=[.7,.9,.7,.5])\n",
        "axs[1,1].set(xlabel='(cov)$^2$',ylabel='Mutual information',title=f'$r=${np.corrcoef(abs(covmi[:,0]),covmi[:,1])[1,0]:.2f}')\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ednz1Vu7aGQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q--tVxI6aGM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 2: Download and process a real dataset"
      ],
      "metadata": {
        "id": "pOyHK7hWvtJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data citation: Sathishkumar V E, Jangwoo Park, and Yongyun Cho. 'Using data mining techniques for bike sharing demand\n",
        "#                prediction in metropolitan city.' Computer Communications, Vol.153, pp.353-366, March, 2020\n",
        "# data source website: https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand\n",
        "\n",
        "# import the data\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00560/SeoulBikeData.csv\"\n",
        "data = pd.read_csv(url,sep=',',encoding='unicode_escape')\n",
        "\n",
        "# let's have a look\n",
        "data"
      ],
      "metadata": {
        "id": "pBiRD8Q7P9lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJW8ijR4Xo6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### data processing 1: convert datetime to days since the first day\n",
        "\n",
        "# new column with different date format\n",
        "data['date'] = pd.to_datetime(data['Date'],format='%d/%m/%Y')\n",
        "\n",
        "# get the first date\n",
        "first_date = data['date'].iloc[0]\n",
        "\n",
        "# subtract and convert to days\n",
        "data['days_since_first'] = (data['date'] - first_date).dt.days\n",
        "\n",
        "\n",
        "### data processing 2: new dataframe with relevant columns\n",
        "columns2use = ['Rented Bike Count','Temperature(Â°C)',\n",
        "               'Wind speed (m/s)','days_since_first',\n",
        "               'Humidity(%)']\n",
        "df = data[columns2use]\n",
        "\n",
        "# dataset size\n",
        "N,M = df.shape\n",
        "\n",
        "# summary statistics\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "LRIsOG0fgTP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = sns.pairplot(df,height=2,\n",
        "             plot_kws=dict(s=3,color=[.7,.7,.9,.7]),\n",
        "             diag_kws=dict(color=[.9,.7,.7]) )\n",
        "h.fig.set_size_inches(12,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tRDKhTOLP9h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eujW9_Z9vycL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 3: Split-half reliability of covariance and mutual information"
      ],
      "metadata": {
        "id": "XWIFqwunvyXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize\n",
        "covariances = np.zeros((M,M,2))\n",
        "mutualinfos = np.zeros((M,M,2))\n",
        "\n",
        "for i in range(M):\n",
        "  for j in range(i,M):\n",
        "\n",
        "    ### EVEN rows\n",
        "    # extract data\n",
        "    x = df[columns2use[i]][::2]\n",
        "    y = df[columns2use[j]][::2]\n",
        "\n",
        "    # covariance\n",
        "    covariances[i,j,0] = np.cov(x,y)[0,1]\n",
        "    covariances[j,i,0] = covariances[i,j,0] # symmetric value can be copied instead of recalculated\n",
        "\n",
        "    # mutual information\n",
        "    mutualinfos[i,j,0] = mutual_info_regression(x.values.reshape(-1,1),y)[0]\n",
        "    mutualinfos[j,i,0] = mutualinfos[i,j,0]\n",
        "\n",
        "\n",
        "    ### ODD rows\n",
        "    # extract data\n",
        "    x = df[columns2use[i]][1::2]\n",
        "    y = df[columns2use[j]][1::2]\n",
        "\n",
        "    # covariance\n",
        "    covariances[i,j,1] = np.cov(x,y)[0,1]\n",
        "    covariances[j,i,1] = covariances[i,j,0]\n",
        "\n",
        "    # mutual information\n",
        "    mutualinfos[i,j,1] = mutual_info_regression(x.values.reshape(-1,1),y)[0]\n",
        "    mutualinfos[j,i,1] = mutualinfos[i,j,0]"
      ],
      "metadata": {
        "id": "qmJaBhRbP9ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axs = plt.subplots(2,3,figsize=(9,6))\n",
        "\n",
        "shortlabels = ['Bikes','Temp','Wind','Days','Humidity']\n",
        "\n",
        "h = axs[0,0].imshow(covariances[:,:,0],cmap='RdBu_r',vmin=-1000,vmax=10000)\n",
        "fig.colorbar(h,ax=axs[0,0],pad=.02,fraction=.046,location='top')\n",
        "axs[0,0].set(title='Covariance (even)\\n\\n',xticks=np.arange(M),xticklabels=shortlabels,yticks=np.arange(M),yticklabels=shortlabels)\n",
        "axs[0,0].tick_params(axis='x',rotation=90)\n",
        "\n",
        "h = axs[0,1].imshow(covariances[:,:,1],cmap='RdBu_r',vmin=-1000,vmax=10000)\n",
        "fig.colorbar(h,ax=axs[0,1],pad=.02,fraction=.046,location='top')\n",
        "axs[0,1].set(title='Covariance (odd)\\n\\n',xticks=np.arange(M),xticklabels=shortlabels,yticks=np.arange(M),yticklabels=shortlabels)\n",
        "axs[0,1].tick_params(axis='x',rotation=90)\n",
        "\n",
        "logcovs = np.log(abs(covariances)) * np.sign(covariances)\n",
        "axs[0,2].plot(logcovs[:,:,0].flatten(),logcovs[:,:,1].flatten(),'ks',markersize=10,markerfacecolor=[.7,.7,.9,.5])\n",
        "axs[0,2].set(xlabel='log(cov) (even rows)',ylabel='log(cov) (odd rows)',title='Covariance correspondences')\n",
        "\n",
        "\n",
        "\n",
        "h = axs[1,0].imshow(mutualinfos[:,:,0],cmap='RdBu_r')\n",
        "fig.colorbar(h,ax=axs[1,0],pad=.02,fraction=.046,location='top')\n",
        "axs[1,0].set(title='Mutual info. (even)\\n\\n',xticks=np.arange(M),xticklabels=shortlabels,yticks=np.arange(M),yticklabels=shortlabels)\n",
        "axs[1,0].tick_params(axis='x',rotation=90)\n",
        "\n",
        "h = axs[1,1].imshow(mutualinfos[:,:,1],cmap='RdBu_r')\n",
        "fig.colorbar(h,ax=axs[1,1],pad=.02,fraction=.046,location='top')\n",
        "axs[1,1].set(title='Mutual info. (odd)\\n\\n',xticks=np.arange(M),xticklabels=shortlabels,yticks=np.arange(M),yticklabels=shortlabels)\n",
        "axs[1,1].tick_params(axis='x',rotation=90)\n",
        "\n",
        "axs[1,2].plot(np.log(mutualinfos[:,:,0].flatten()),np.log(mutualinfos[:,:,1].flatten()),'ks',markersize=10,markerfacecolor=[.7,.7,.9,.5])\n",
        "axs[1,2].set(xlabel='log(MI) (even rows)',ylabel='log(MI) (odd rows)',title='MI correspondences')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_gEsCQYhP9bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indices of unique elements\n",
        "uniqueIdx = np.triu_indices(M,k=1)\n",
        "\n",
        "# vectors for unique elements from average of test-retest\n",
        "uniqueCovs = np.log(covariances**2).mean(axis=-1)[uniqueIdx]\n",
        "uniqueMIs  = np.log(mutualinfos).mean(axis=-1)[uniqueIdx]\n",
        "\n",
        "# their correlation\n",
        "r = np.corrcoef(uniqueCovs,uniqueMIs)[0,1]\n",
        "\n",
        "# visualize\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(uniqueCovs,uniqueMIs,'wh',markersize=13,markerfacecolor=[.7,.7,.9,.5])\n",
        "plt.gca().set(xlabel='Signed log(cov)',ylabel='log(MI)',title=f'$r$ = {r:.3f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aNgvCa7jh-VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwJf_mLeaCjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 4: Statistical significances"
      ],
      "metadata": {
        "id": "LSuOmC00u-w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 500 # 5 mins with all rows\n",
        "permuted_vals = np.zeros(n_iters)\n",
        "\n",
        "# initialize\n",
        "zvals = np.zeros((M,M,2))\n",
        "pvals = np.zeros((M,M,2))\n",
        "\n",
        "for i in range(M):\n",
        "  for j in range(i+1,M):\n",
        "\n",
        "    ### extract data\n",
        "    x = df[columns2use[i]].values[::55]\n",
        "    y = df[columns2use[j]].values[::55]\n",
        "    N = len(x)\n",
        "\n",
        "    ### COVARIANCE: permutation distribution\n",
        "    for permi in range(n_iters):\n",
        "      shuffle_idx = np.random.permutation(N)\n",
        "      permuted_vals[permi] = np.cov(x[shuffle_idx],y)[0,1]\n",
        "\n",
        "    # get statistical values\n",
        "    c = np.cov(x,y)[0,1]\n",
        "    zvals[i,j,0] = (c-permuted_vals.mean()) / permuted_vals.std(ddof=1)\n",
        "    pvals[i,j,0] = np.sum( abs(permuted_vals) > abs(c) ) / n_iters\n",
        "\n",
        "\n",
        "    ### MUTUAL INFORMATION\n",
        "    for permi in range(n_iters):\n",
        "      shuffle_idx = np.random.permutation(N)\n",
        "      x_shuffled = x[shuffle_idx].reshape(-1,1)\n",
        "      permuted_vals[permi] = mutual_info_regression(x_shuffled,y)[0]\n",
        "\n",
        "    # get statistical values\n",
        "    mi = mutual_info_regression(x.reshape(-1,1),y)[0]\n",
        "    zvals[i,j,1] = (mi-permuted_vals.mean()) / permuted_vals.std(ddof=1)\n",
        "    pvals[i,j,1] = np.sum( permuted_vals > mi ) / n_iters\n"
      ],
      "metadata": {
        "id": "IWpui58pu-tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axs = plt.subplots(1,2,figsize=(9,4))\n",
        "\n",
        "# significance threshold, corrected for multiple comparisons\n",
        "sigthresh = .05 / (M*(M-1)/2)\n",
        "\n",
        "# loop over the analyses\n",
        "for i in range(2):\n",
        "\n",
        "  # replace \"missing\" tests with nan\n",
        "  Z = zvals[:,:,i]\n",
        "  Z[Z==0] = np.nan\n",
        "\n",
        "  # visualize the statistical z-scores\n",
        "  h = axs[i].imshow(Z,vmin=-3,vmax=3,cmap='RdBu_r')\n",
        "  fig.colorbar(h,ax=axs[i],pad=.02,fraction=.046)\n",
        "  axs[i].set(xticks=np.arange(M),xticklabels=shortlabels,yticks=np.arange(M),yticklabels=shortlabels)\n",
        "\n",
        "  # show significance\n",
        "  for j in range(M):\n",
        "    for k in range(j+1,M):\n",
        "      if pvals[j,k,i] < sigthresh:\n",
        "        axs[i].text(k,j,'*',fontsize=18,ha='center',va='center')\n",
        "\n",
        "axs[0].set(title=f'Covariance z-scores\\n(N={N})')\n",
        "axs[1].set(title=f'Mutual info. z-scores\\n(N={N})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GnBoDigaTkyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparison of cov/mi values in the subset vs full dataset\n",
        "\n",
        "# initialize\n",
        "CovVals = np.zeros((M,M,2))\n",
        "MI_Vals = np.zeros((M,M,2))\n",
        "\n",
        "for i in range(M):\n",
        "  for j in range(i+1,M):\n",
        "\n",
        "    ### small dataset\n",
        "    x = df[columns2use[i]].values[::55]\n",
        "    y = df[columns2use[j]].values[::55]\n",
        "    CovVals[i,j,0] = np.cov(x,y)[0,1]\n",
        "    MI_Vals[i,j,0] = mutual_info_regression(x.reshape(-1,1),y)[0]\n",
        "    smallN = len(x)\n",
        "\n",
        "    ### full dataset\n",
        "    x = df[columns2use[i]].values\n",
        "    y = df[columns2use[j]].values\n",
        "    CovVals[i,j,1] = np.cov(x,y)[0,1]\n",
        "    MI_Vals[i,j,1] = mutual_info_regression(x.reshape(-1,1),y)[0]\n",
        "    bigN = len(x)\n",
        "\n",
        "# transform to signed log\n",
        "CovVals = np.log(abs(CovVals)) * np.sign(CovVals)"
      ],
      "metadata": {
        "id": "-85I-rtZu-oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axs = plt.subplots(1,2,figsize=(8,3))\n",
        "\n",
        "# visual comparison\n",
        "axs[0].plot(CovVals[:,:,0].flatten(),CovVals[:,:,1].flatten(),'wh',markersize=10,markerfacecolor=[.7,.7,.9,.5])\n",
        "axs[0].plot([np.nanmin(CovVals),np.nanmax(CovVals)],[np.nanmin(CovVals),np.nanmax(CovVals)],'w--',zorder=-14,linewidth=.3)\n",
        "axs[0].set(xlabel=f'N = {smallN} rows',ylabel=f'N = {bigN} rows',title='Signed log(cov) correspondences')\n",
        "\n",
        "axs[1].plot(MI_Vals[:,:,0].flatten(),MI_Vals[:,:,1].flatten(),'wh',markersize=10,markerfacecolor=[.9,.7,.7,.5])\n",
        "axs[1].plot([np.nanmin(MI_Vals),np.nanmax(MI_Vals)],[np.nanmin(MI_Vals),np.nanmax(MI_Vals)],'w--',zorder=-14,linewidth=.3)\n",
        "axs[1].set(xlabel=f'N = {smallN} rows',ylabel=f'N = {bigN} rows',title='Mutual info. correspondences')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k0UEahlO57DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X11w6dMZ56nM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}